{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ml456v0q3bSi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the correct path to your dataset\n",
        "file_path = '/content/colon-dataset-processed.csv'\n"
      ],
      "metadata": {
        "id": "mrCYfQal39Dt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your data\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Split the data into features and labels\n",
        "X = data.drop('Class', axis=1)\n",
        "y = data['Class']\n",
        "\n",
        "# Encode the labels if they are categorical (assuming 'healthy' is 0 and 'diagnosed' is 1)\n",
        "y = y.map({'healthy': 0, 'diagnosed': 1})"
      ],
      "metadata": {
        "id": "SzrnT5uU4LtK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a Decision Tree Model"
      ],
      "metadata": {
        "id": "j1ju__rLgo7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create the decision tree classifier and fit it to the training data\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the classifier\n",
        "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
        "print(f'Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}')\n",
        "print(f'Classification Report:\\n{classification_report(y_test, y_pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaDhyP5A4Stn",
        "outputId": "7ba8922b-a39f-457a-fdb0-6bac1c18a2ea"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.782608695652174\n",
            "Confusion Matrix:\n",
            "[[9 2]\n",
            " [3 9]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.82      0.78        11\n",
            "           1       0.82      0.75      0.78        12\n",
            "\n",
            "    accuracy                           0.78        23\n",
            "   macro avg       0.78      0.78      0.78        23\n",
            "weighted avg       0.79      0.78      0.78        23\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trying to Construct a DT from scratch insteadf of a liberary.\n",
        "resulted in much higher accuracy."
      ],
      "metadata": {
        "id": "BkTuzyH9gzfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "class Node:\n",
        "    def __init__(self, gini, num_samples, num_samples_per_class, predicted_class):\n",
        "        self.gini = gini\n",
        "        self.num_samples = num_samples\n",
        "        self.num_samples_per_class = num_samples_per_class\n",
        "        self.predicted_class = predicted_class\n",
        "        self.feature_index = 0\n",
        "        self.threshold = 0\n",
        "        self.left = None\n",
        "        self.right = None\n",
        "\n",
        "def gini_impurity(y):\n",
        "    m = len(y)\n",
        "    return 1.0 - sum((np.sum(y == c) / m) ** 2 for c in range(2))\n",
        "\n",
        "def grow_tree(X, y, depth=0, max_depth=None):\n",
        "    num_samples_per_class = [np.sum(y == i) for i in range(2)]\n",
        "    predicted_class = np.argmax(num_samples_per_class)\n",
        "    node = Node(\n",
        "        gini=gini_impurity(y),\n",
        "        num_samples=len(y),\n",
        "        num_samples_per_class=num_samples_per_class,\n",
        "        predicted_class=predicted_class,\n",
        "    )\n",
        "\n",
        "    if depth < max_depth:\n",
        "        idx, thr = best_split(X, y)\n",
        "        if idx is not None:\n",
        "            indices_left = X[:, idx] < thr\n",
        "            X_left, y_left = X[indices_left], y[indices_left]\n",
        "            X_right, y_right = X[~indices_left], y[~indices_left]\n",
        "            node.feature_index = idx\n",
        "            node.threshold = thr\n",
        "            node.left = grow_tree(X_left, y_left, depth + 1, max_depth)\n",
        "            node.right = grow_tree(X_right, y_right, depth + 1, max_depth)\n",
        "    return node\n",
        "\n",
        "def best_split(X, y):\n",
        "    m, n = X.shape\n",
        "    if m <= 1:\n",
        "        return None, None\n",
        "\n",
        "    num_parent = [np.sum(y == c) for c in range(2)]\n",
        "    best_gini = 1.0 - sum((num / m) ** 2 for num in num_parent)\n",
        "    best_idx, best_thr = None, None\n",
        "\n",
        "    for idx in range(n):\n",
        "        thresholds, classes = zip(*sorted(zip(X[:, idx], y)))\n",
        "        num_left = [0] * 2\n",
        "        num_right = num_parent.copy()\n",
        "        for i in range(1, m):\n",
        "            c = classes[i - 1]\n",
        "            num_left[c] += 1\n",
        "            num_right[c] -= 1\n",
        "            gini_left = 1.0 - sum(\n",
        "                (num_left[x] / i) ** 2 for x in range(2)\n",
        "            )\n",
        "            gini_right = 1.0 - sum(\n",
        "                (num_right[x] / (m - i)) ** 2 for x in range(2)\n",
        "            )\n",
        "            gini = (i * gini_left + (m - i) * gini_right) / m\n",
        "            if thresholds[i] == thresholds[i - 1]:\n",
        "                continue\n",
        "            if gini < best_gini:\n",
        "                best_gini = gini\n",
        "                best_idx = idx\n",
        "                best_thr = (thresholds[i] + thresholds[i - 1]) / 2\n",
        "    return best_idx, best_thr\n",
        "\n",
        "def predict_sample(node, X):\n",
        "    if node.left is None and node.right is None:\n",
        "        return node.predicted_class\n",
        "    if X[node.feature_index] < node.threshold:\n",
        "        return predict_sample(node.left, X)\n",
        "    else:\n",
        "        return predict_sample(node.right, X)\n",
        "\n",
        "def predict_tree(node, X):\n",
        "    return [predict_sample(node, x) for x in X]\n",
        "\n",
        "# Load your data\n",
        "data = pd.read_csv('/content/colon-dataset-processed.csv')\n",
        "X = data.drop('Class', axis=1).values\n",
        "y = data['Class'].map({'healthy': 0, 'diagnosed': 1}).values\n",
        "\n",
        "# Train the decision tree\n",
        "tree = grow_tree(X, y, max_depth=3)\n",
        "\n",
        "# Predict samples\n",
        "predictions = predict_tree(tree, X)\n",
        "\n",
        "\n",
        "\n",
        "# Generate the confusion matrix\n",
        "conf_matrix = confusion_matrix(y, predictions)\n",
        "\n",
        "# Print the confusion matrix\n",
        "conf_matrix = confusion_matrix(y, predictions)\n",
        "print('Confusion matrix:')\n",
        "print(conf_matrix)\n",
        "\n",
        "# Generate and print the classification report\n",
        "class_report = classification_report(y, predictions)\n",
        "print('\\nClassification report:')\n",
        "print(class_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eGzndY762Bk",
        "outputId": "6ec56c17-e57b-4816-ff80-f246e0016011"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix:\n",
            "[[47  3]\n",
            " [ 9 56]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.94      0.89        50\n",
            "           1       0.95      0.86      0.90        65\n",
            "\n",
            "    accuracy                           0.90       115\n",
            "   macro avg       0.89      0.90      0.90       115\n",
            "weighted avg       0.90      0.90      0.90       115\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Highest accurasy with optinazation techniques :"
      ],
      "metadata": {
        "id": "6omkohathKwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "import pandas as pd\n",
        "\n",
        "# Load your data\n",
        "data = pd.read_csv('/content/colon-dataset-processed.csv')\n",
        "X = data.drop('Class', axis=1).values\n",
        "y = data['Class'].map({'healthy': 0, 'diagnosed': 1}).values\n",
        "\n",
        "# Standardize the data (if needed)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Set up the parameter grid to search\n",
        "param_grid = {\n",
        "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
        "    'min_samples_split': [2, 5, 10, 20],\n",
        "    'min_samples_leaf': [1, 2, 4, 8],\n",
        "    'max_features': [None, 'sqrt', 'log2'],\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "# Create the grid search object\n",
        "grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=10, n_jobs=-1, verbose=1)\n",
        "\n",
        "# Fit the model to the training data\n",
        "grid_search.fit(X_scaled, y)\n",
        "\n",
        "# Evaluate the best model found by the grid search\n",
        "best_tree_clf = grid_search.best_estimator_\n",
        "y_pred = best_tree_clf.predict(X_scaled)\n",
        "\n",
        "# Predict the labels for the dataset\n",
        "y_pred = best_tree_clf.predict(X_scaled)\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = accuracy_score(y, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "\n",
        "# Generate the confusion matrix\n",
        "conf_matrix = confusion_matrix(y, y_pred)\n",
        "print('Confusion matrix:')\n",
        "print(conf_matrix)\n",
        "\n",
        "# Generate and print the classification report\n",
        "class_report = classification_report(y, y_pred)\n",
        "print('\\nClassification report:')\n",
        "print(class_report)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFqx5Jyv-BaX",
        "outputId": "1bcf6cc7-20d3-4610-80ca-d8cf81b3c0ef"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 10 folds for each of 576 candidates, totalling 5760 fits\n",
            "Accuracy: 0.90\n",
            "Confusion matrix:\n",
            "[[45  5]\n",
            " [ 6 59]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.90      0.89        50\n",
            "           1       0.92      0.91      0.91        65\n",
            "\n",
            "    accuracy                           0.90       115\n",
            "   macro avg       0.90      0.90      0.90       115\n",
            "weighted avg       0.90      0.90      0.90       115\n",
            "\n"
          ]
        }
      ]
    }
  ]
}