{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ml456v0q3bSi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mrCYfQal39Dt"
      },
      "outputs": [],
      "source": [
        "# Specify the correct path to your dataset\n",
        "file_path = '/content/colon-dataset-processed.csv'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SzrnT5uU4LtK"
      },
      "outputs": [],
      "source": [
        "# Load your data\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Split the data into features and labels\n",
        "X = data.drop('Class', axis=1)\n",
        "y = data['Class']\n",
        "\n",
        "# Encode the labels if they are categorical (assuming 'healthy' is 0 and 'diagnosed' is 1)\n",
        "y = y.map({'healthy': 0, 'diagnosed': 1})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1ju__rLgo7J"
      },
      "source": [
        "Creating a Decision Tree Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaDhyP5A4Stn",
        "outputId": "7ba8922b-a39f-457a-fdb0-6bac1c18a2ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.782608695652174\n",
            "Confusion Matrix:\n",
            "[[9 2]\n",
            " [3 9]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.82      0.78        11\n",
            "           1       0.82      0.75      0.78        12\n",
            "\n",
            "    accuracy                           0.78        23\n",
            "   macro avg       0.78      0.78      0.78        23\n",
            "weighted avg       0.79      0.78      0.78        23\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create the decision tree classifier and fit it to the training data\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the classifier\n",
        "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
        "print(f'Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}')\n",
        "print(f'Classification Report:\\n{classification_report(y_test, y_pred)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkTuzyH9gzfM"
      },
      "source": [
        "Trying to Construct a DT from scratch insteadf of a liberary.\n",
        "resulted in much higher accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eGzndY762Bk",
        "outputId": "6ec56c17-e57b-4816-ff80-f246e0016011"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion matrix:\n",
            "[[47  3]\n",
            " [ 9 56]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.94      0.89        50\n",
            "           1       0.95      0.86      0.90        65\n",
            "\n",
            "    accuracy                           0.90       115\n",
            "   macro avg       0.89      0.90      0.90       115\n",
            "weighted avg       0.90      0.90      0.90       115\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "class Node:\n",
        "    def __init__(self, gini, num_samples, num_samples_per_class, predicted_class):\n",
        "        self.gini = gini\n",
        "        self.num_samples = num_samples\n",
        "        self.num_samples_per_class = num_samples_per_class\n",
        "        self.predicted_class = predicted_class\n",
        "        self.feature_index = 0\n",
        "        self.threshold = 0\n",
        "        self.left = None\n",
        "        self.right = None\n",
        "\n",
        "def gini_impurity(y):\n",
        "    m = len(y)\n",
        "    return 1.0 - sum((np.sum(y == c) / m) ** 2 for c in range(2))\n",
        "\n",
        "def grow_tree(X, y, depth=0, max_depth=None):\n",
        "    num_samples_per_class = [np.sum(y == i) for i in range(2)]\n",
        "    predicted_class = np.argmax(num_samples_per_class)\n",
        "    node = Node(\n",
        "        gini=gini_impurity(y),\n",
        "        num_samples=len(y),\n",
        "        num_samples_per_class=num_samples_per_class,\n",
        "        predicted_class=predicted_class,\n",
        "    )\n",
        "\n",
        "    if depth < max_depth:\n",
        "        idx, thr = best_split(X, y)\n",
        "        if idx is not None:\n",
        "            indices_left = X[:, idx] < thr\n",
        "            X_left, y_left = X[indices_left], y[indices_left]\n",
        "            X_right, y_right = X[~indices_left], y[~indices_left]\n",
        "            node.feature_index = idx\n",
        "            node.threshold = thr\n",
        "            node.left = grow_tree(X_left, y_left, depth + 1, max_depth)\n",
        "            node.right = grow_tree(X_right, y_right, depth + 1, max_depth)\n",
        "    return node\n",
        "\n",
        "def best_split(X, y):\n",
        "    m, n = X.shape\n",
        "    if m <= 1:\n",
        "        return None, None\n",
        "\n",
        "    num_parent = [np.sum(y == c) for c in range(2)]\n",
        "    best_gini = 1.0 - sum((num / m) ** 2 for num in num_parent)\n",
        "    best_idx, best_thr = None, None\n",
        "\n",
        "    for idx in range(n):\n",
        "        thresholds, classes = zip(*sorted(zip(X[:, idx], y)))\n",
        "        num_left = [0] * 2\n",
        "        num_right = num_parent.copy()\n",
        "        for i in range(1, m):\n",
        "            c = classes[i - 1]\n",
        "            num_left[c] += 1\n",
        "            num_right[c] -= 1\n",
        "            gini_left = 1.0 - sum(\n",
        "                (num_left[x] / i) ** 2 for x in range(2)\n",
        "            )\n",
        "            gini_right = 1.0 - sum(\n",
        "                (num_right[x] / (m - i)) ** 2 for x in range(2)\n",
        "            )\n",
        "            gini = (i * gini_left + (m - i) * gini_right) / m\n",
        "            if thresholds[i] == thresholds[i - 1]:\n",
        "                continue\n",
        "            if gini < best_gini:\n",
        "                best_gini = gini\n",
        "                best_idx = idx\n",
        "                best_thr = (thresholds[i] + thresholds[i - 1]) / 2\n",
        "    return best_idx, best_thr\n",
        "\n",
        "def predict_sample(node, X):\n",
        "    if node.left is None and node.right is None:\n",
        "        return node.predicted_class\n",
        "    if X[node.feature_index] < node.threshold:\n",
        "        return predict_sample(node.left, X)\n",
        "    else:\n",
        "        return predict_sample(node.right, X)\n",
        "\n",
        "def predict_tree(node, X):\n",
        "    return [predict_sample(node, x) for x in X]\n",
        "\n",
        "# Load your data\n",
        "data = pd.read_csv('colon-dataset-processed.csv')\n",
        "X = data.drop('Class', axis=1).values\n",
        "y = data['Class'].map({'healthy': 0, 'diagnosed': 1}).values\n",
        "\n",
        "# Train the decision tree\n",
        "tree = grow_tree(X, y, max_depth=3)\n",
        "\n",
        "# Predict samples\n",
        "predictions = predict_tree(tree, X)\n",
        "\n",
        "\n",
        "\n",
        "# Generate the confusion matrix\n",
        "conf_matrix = confusion_matrix(y, predictions)\n",
        "\n",
        "# Print the confusion matrix\n",
        "conf_matrix = confusion_matrix(y, predictions)\n",
        "print('Confusion matrix:')\n",
        "print(conf_matrix)\n",
        "\n",
        "# Generate and print the classification report\n",
        "class_report = classification_report(y, predictions)\n",
        "print('\\nClassification report:')\n",
        "print(class_report)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here I did some modification to the DT to Handle cases where no valid split can be found by turning the node into a leaf.\n",
        "Stop growing the tree if all samples at a node have the same class label. the changes made the code more robust, however the accuracy decreased to 81%, still higher then using the liberary "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion matrix:\n",
            "[[ 9  5]\n",
            " [ 0 12]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.64      0.78        14\n",
            "           1       0.71      1.00      0.83        12\n",
            "\n",
            "    accuracy                           0.81        26\n",
            "   macro avg       0.85      0.82      0.81        26\n",
            "weighted avg       0.86      0.81      0.80        26\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from imblearn.over_sampling import SMOTE  # Make sure you've installed imblearn\n",
        "\n",
        "# ... [No change to the Node class, gini_impurity, predict_sample functions] ...\n",
        "\n",
        "# Define your CustomDecisionTree class\n",
        "class CustomDecisionTree(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, max_depth=None):\n",
        "        self.max_depth = max_depth\n",
        "        self.tree_ = None\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        # Ensure X and y are numpy arrays to satisfy the indexing used in grow_tree\n",
        "        X, y = np.array(X), np.array(y)\n",
        "        self.tree_ = grow_tree(X, y, max_depth=self.max_depth)\n",
        "        return self\n",
        "    \n",
        "    def predict(self, X):\n",
        "        # Ensure X is a numpy array\n",
        "        X = np.array(X)\n",
        "        return predict_tree(self.tree_, X)\n",
        "\n",
        "# ... [No changes to the grow_tree, best_split functions] ...\n",
        "\n",
        "# Load your data\n",
        "data = pd.read_csv('colon-dataset-processed.csv')\n",
        "X = data.drop('Class', axis=1)\n",
        "y = data['Class'].map({'healthy': 0, 'diagnosed': 1})\n",
        "\n",
        "# Balance the dataset using SMOTE\n",
        "smote = SMOTE()\n",
        "X_balanced, y_balanced = smote.fit_resample(X, y)\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert the pandas dataframe to numpy array for compatibility with our custom tree\n",
        "X_train = X_train.values\n",
        "X_test = X_test.values\n",
        "\n",
        "# Find the best max_depth using cross-validation\n",
        "best_accuracy = 0\n",
        "best_depth = 0\n",
        "kf = StratifiedKFold(n_splits=5)\n",
        "for depth in range(1, 10):\n",
        "    tree = CustomDecisionTree(max_depth=depth)\n",
        "    scores = cross_val_score(tree, X_train, y_train, cv=kf)\n",
        "    if np.mean(scores) > best_accuracy:\n",
        "        best_accuracy = np.mean(scores)\n",
        "        best_depth = depth\n",
        "\n",
        "# Train the decision tree with the best max_depth\n",
        "tree = CustomDecisionTree(max_depth=best_depth)\n",
        "tree.fit(X_train, y_train)\n",
        "\n",
        "# Predict samples on the test set\n",
        "predictions = tree.predict(X_test)\n",
        "\n",
        "# Generate and evaluate the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, predictions)\n",
        "print('Confusion matrix:')\n",
        "print(conf_matrix)\n",
        "\n",
        "# Generate and evaluate the classification report\n",
        "class_report = classification_report(y_test, predictions)\n",
        "print('\\nClassification report:')\n",
        "print(class_report)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
